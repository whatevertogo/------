{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e34162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import requests\n",
    "\n",
    "# 设置随机种子\n",
    "#torch.manual_seed(42)\n",
    "#np.random.seed(42)\n",
    "\n",
    "# 检查CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "def check_internet_connection():\n",
    "    try:\n",
    "        requests.get(\"https://huggingface.co\", timeout=5)\n",
    "        print(\"网络连接正常。\")\n",
    "    except requests.ConnectionError:\n",
    "        print(\"网络连接失败，请检查网络。\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67997b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义collate_fn，将InputExample对象转换为适合模型输入的格式。\n",
    "    \"\"\"\n",
    "    sentences1 = [example.texts[0] for example in batch]\n",
    "    sentences2 = [example.texts[1] for example in batch]\n",
    "    labels = [example.label for example in batch]\n",
    "    return {\n",
    "        'sentences1': sentences1,\n",
    "        'sentences2': sentences2,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "class SentencePairDataset:\n",
    "    def __init__(self, sentences1, sentences2, labels):\n",
    "        self.examples = [InputExample(texts=[s1, s2], label=float(label))\n",
    "                         for s1, s2, label in zip(sentences1, sentences2, labels)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def evaluate(model, data_loader, device, threshold=0.84):\n",
    "    \"\"\"\n",
    "    高效评估函数，批量编码所有句子对并计算相似度。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings1 = []\n",
    "    all_embeddings2 = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 批量编码所有句子对\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            sentences1 = batch['sentences1']\n",
    "            sentences2 = batch['sentences2']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            embeddings1 = model.encode(sentences1, convert_to_tensor=True, device=device)\n",
    "            embeddings2 = model.encode(sentences2, convert_to_tensor=True, device=device)\n",
    "\n",
    "            all_embeddings1.append(embeddings1)\n",
    "            all_embeddings2.append(embeddings2)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # 将所有嵌入拼接为单个张量\n",
    "    all_embeddings1 = torch.cat(all_embeddings1, dim=0)\n",
    "    all_embeddings2 = torch.cat(all_embeddings2, dim=0)\n",
    "    all_labels = torch.tensor(all_labels, dtype=torch.int, device=device)\n",
    "\n",
    "    # 一次性计算余弦相似度\n",
    "    similarity = torch.cosine_similarity(all_embeddings1, all_embeddings2, dim=1)\n",
    "    preds = (similarity > threshold).cpu().numpy().astype(int)\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(all_labels.cpu().numpy(), preds)\n",
    "    f1 = f1_score(all_labels.cpu().numpy(), preds)\n",
    "    recall = recall_score(all_labels.cpu().numpy(), preds)\n",
    "    score = 0.6 * f1 + 0.2 * accuracy + 0.2 * recall\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "        'score': score\n",
    "    }\n",
    "\n",
    "def train_model(model, train_data, val_data, device, batch_size=64, epochs=3, patience=3, min_delta=1e-4):\n",
    "    \"\"\"\n",
    "    完全重写的训练函数，解决卡住的问题\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    print(f\"模型是否在GPU上: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # 准备数据集\n",
    "    print(\"准备训练数据集...\")\n",
    "    train_dataset = SentencePairDataset(\n",
    "        train_data['q1'].tolist(),\n",
    "        train_data['q2'].tolist(),\n",
    "        train_data['label'].tolist()\n",
    "    )\n",
    "    print(\"准备验证数据集...\")\n",
    "    val_dataset = SentencePairDataset(\n",
    "        val_data['q1'].tolist(),\n",
    "        val_data['q2'].tolist(),\n",
    "        val_data['label'].tolist()\n",
    "    )\n",
    "    \n",
    "    # 数据加载器\n",
    "    print(\"创建数据加载器...\")\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # Windows下使用0避免多进程问题\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,  # 使用相同的batch大小\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # Windows下使用0避免多进程问题\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    # 优化器和损失函数\n",
    "    print(\"初始化优化器和损失函数...\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    train_loss = losses.CosineSimilarityLoss(model)\n",
    "    best_score = 0\n",
    "    no_improve_epochs = 0\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    print(\"开始训练循环...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        progress_bar = tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        try:\n",
    "            for batch_idx, batch in enumerate(train_dataloader):\n",
    "                # 获取数据\n",
    "                sentences1 = batch['sentences1']\n",
    "                sentences2 = batch['sentences2']\n",
    "                labels = torch.tensor(batch['labels'], dtype=torch.float32, device=device)\n",
    "\n",
    "                # 清除梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 将句子转换为模型输入格式\n",
    "                features1 = model.tokenize(sentences1)\n",
    "                features2 = model.tokenize(sentences2)\n",
    "\n",
    "                # 将输入移动到设备上\n",
    "                features1 = {key: val.to(device) for key, val in features1.items()}\n",
    "                features2 = {key: val.to(device) for key, val in features2.items()}\n",
    "\n",
    "                # 计算余弦相似度损失\n",
    "                loss = train_loss([features1, features2], labels)\n",
    "\n",
    "                # 反向传播\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 更新进度条\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.update(1)\n",
    "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            # 进行验证\n",
    "            val_metrics = evaluate(model, val_dataloader, device)\n",
    "            current_score = val_metrics['score']\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            print(f\"验证集评估: Accuracy={val_metrics['accuracy']:.4f}, \"\n",
    "                  f\"F1={val_metrics['f1']:.4f}, Recall={val_metrics['recall']:.4f}\")\n",
    "            print(f\"当前得分: {current_score:.4f}\")\n",
    "            \n",
    "            # 保存每个epoch的模型\n",
    "            epoch_save_path = f'model_epoch_{epoch+1}'\n",
    "            print(f\"保存当前epoch模型到: {epoch_save_path}\")\n",
    "            model.save(epoch_save_path)\n",
    "            \n",
    "            # 检查是否需要保存最佳模型\n",
    "            if current_score > best_score + min_delta:\n",
    "                best_score = current_score\n",
    "                no_improve_epochs = 0\n",
    "                print(f\"保存最佳模型，得分: {best_score:.4f}\")\n",
    "                model.save('best_model')\n",
    "            else:\n",
    "                no_improve_epochs += 1\n",
    "                print(f\"模型表现未提升，已经 {no_improve_epochs}/{patience} 个epoch\")\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"\\nEarly stopping triggered\")\n",
    "                    break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"训练过程中出错: {e}\")\n",
    "            progress_bar.close()\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a645d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n",
      "训练集大小: 214889\n",
      "验证集大小: 23877\n",
      "测试集大小: 4401\n",
      "\n",
      "训练集类别分布:\n",
      "label\n",
      "1    124686\n",
      "0     90203\n",
      "Name: count, dtype: int64\n",
      "训练集大小: 214889\n",
      "验证集大小: 23877\n",
      "测试集大小: 4401\n",
      "\n",
      "训练集类别分布:\n",
      "label\n",
      "1    124686\n",
      "0     90203\n",
      "Name: count, dtype: int64\n",
      "网络连接正常。\n",
      "\n",
      "加载预训练模型...\n",
      "网络连接正常。\n",
      "\n",
      "加载预训练模型...\n",
      "预训练模型加载成功！\n",
      "\n",
      "开始训练...\n",
      "模型是否在GPU上: cuda:0\n",
      "准备训练数据集...\n",
      "预训练模型加载成功！\n",
      "\n",
      "开始训练...\n",
      "模型是否在GPU上: cuda:0\n",
      "准备训练数据集...\n",
      "准备验证数据集...\n",
      "创建数据加载器...\n",
      "初始化优化器和损失函数...\n",
      "开始训练循环...\n",
      "准备验证数据集...\n",
      "创建数据加载器...\n",
      "初始化优化器和损失函数...\n",
      "开始训练循环...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 3358/3358 [1:40:29<00:00,  1.69s/it, loss=0.0923]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "验证集评估: Accuracy=0.8953, F1=0.9044, Recall=0.8520\n",
      "当前得分: 0.8921\n",
      "保存当前epoch模型到: model_epoch_1\n",
      "保存最佳模型，得分: 0.8921\n",
      "保存最佳模型，得分: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 3358/3358 [1:41:03<00:00,  1.81s/it, loss=0.0923]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "验证集评估: Accuracy=0.8960, F1=0.9055, Recall=0.8564\n",
      "当前得分: 0.8938\n",
      "保存当前epoch模型到: model_epoch_2\n",
      "保存最佳模型，得分: 0.8938\n",
      "保存最佳模型，得分: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 3358/3358 [1:42:13<00:00,  1.83s/it, loss=0.0734]\n",
      "\n",
      "Epoch 3/3: 100%|██████████| 3358/3358 [1:41:08<00:00,  1.80s/it, loss=0.0962]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3\n",
      "验证集评估: Accuracy=0.9024, F1=0.9119, Recall=0.8679\n",
      "当前得分: 0.9012\n",
      "保存当前epoch模型到: model_epoch_3\n",
      "保存最佳模型，得分: 0.9012\n",
      "保存最佳模型，得分: 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 3358/3358 [1:43:59<00:00,  1.86s/it, loss=0.0962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "加载最佳模型进行测试...\n",
      "模型加载成功\n",
      "准备测试集...\n",
      "进行最终测试...\n",
      "测试完成\n",
      "\n",
      "最终测试结果:\n",
      "Accuracy: 0.8603\n",
      "F1-score: 0.8510\n",
      "Recall: 0.7850\n",
      "最终得分: 0.8396\n",
      "\n",
      "模型已保存为: chinese_semantic_model_final\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. 加载数据\n",
    "    print(\"加载数据...\")\n",
    "    data = pd.read_csv('csv/train.tsv', sep='\\t', header=None, names=['q1', 'q2', 'label'])\n",
    "    test_data = pd.read_csv('csv/test.csv', sep='\\t', header=None, names=['q1', 'q2', 'label'])\n",
    "\n",
    "    # 拆分训练集和验证集\n",
    "    train_data, val_data = train_test_split(data, test_size=0.1)\n",
    "\n",
    "    print(f\"训练集大小: {len(train_data)}\")\n",
    "    print(f\"验证集大小: {len(val_data)}\")\n",
    "    print(f\"测试集大小: {len(test_data)}\")\n",
    "    print(\"\\n训练集类别分布:\")\n",
    "    print(train_data['label'].value_counts())\n",
    "\n",
    "    # 2. 检查网络连接\n",
    "    if not check_internet_connection():\n",
    "        return\n",
    "\n",
    "    # 3. 加载模型\n",
    "    print(\"\\n加载预训练模型...\")\n",
    "    try:\n",
    "        model = SentenceTransformer('shibing624/text2vec-base-chinese')\n",
    "        print(\"预训练模型加载成功！\")\n",
    "    except Exception as e:\n",
    "        print(f\"预训练模型加载失败: {e}\")\n",
    "        print(\"请检查网络连接或模型名称是否正确。\")\n",
    "        return\n",
    "\n",
    "    # 4. 训练模型\n",
    "    print(\"\\n开始训练...\")\n",
    "    model = train_model(model, train_data, val_data, device, \n",
    "                   batch_size=64,  # 可以根据GPU显存调整\n",
    "                   epochs=3,\n",
    "                   patience=3)\n",
    "\n",
    "    # 5. 加载最佳模型进行测试\n",
    "    print(\"\\n加载最佳模型进行测试...\")\n",
    "    try:\n",
    "        model = SentenceTransformer('best_model')\n",
    "        print(\"模型加载成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"模型加载失败: {e}\")\n",
    "        return\n",
    "\n",
    "    # 6. 准备测试集\n",
    "    print(\"准备测试集...\")\n",
    "    test_dataset = SentencePairDataset(\n",
    "        test_data['q1'].tolist(),\n",
    "        test_data['q2'].tolist(),\n",
    "        test_data['label'].tolist()\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=96, \n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # 不使用多进程\n",
    "        collate_fn=custom_collate_fn  # 使用自定义的collate_fn\n",
    "    )\n",
    "\n",
    "    # 7. 最终测试\n",
    "    print(\"进行最终测试...\")\n",
    "    try:\n",
    "        test_metrics = evaluate(model, test_loader, device)\n",
    "        print(\"测试完成\")\n",
    "    except Exception as e:\n",
    "        print(f\"测试失败: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n最终测试结果:\")\n",
    "    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1-score: {test_metrics['f1']:.4f}\")\n",
    "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"最终得分: {test_metrics['score']:.4f}\")\n",
    "\n",
    "    # 8. 保存最终模型\n",
    "    model.save('chinese_semantic_model_final')\n",
    "    print(\"\\n模型已保存为: chinese_semantic_model_final\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ce3c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "加载测试数据...\n",
      "测试集大小: 4401\n",
      "\n",
      "加载模型 best_model...\n",
      "模型加载成功\n",
      "模型是否在GPU上: cuda:0\n",
      "准备测试集...\n",
      "进行测试评估...\n",
      "\n",
      "测试结果:\n",
      "Accuracy: 0.8603\n",
      "F1-score: 0.8510\n",
      "Recall: 0.7850\n",
      "最终得分: 0.8396\n",
      "\n",
      "尝试不同阈值:\n",
      "阈值=0.840: Accuracy=0.8603, F1=0.8510, Recall=0.7850, Score=0.8396\n",
      "阈值=0.845: Accuracy=0.8573, F1=0.8470, Recall=0.7769, Score=0.8350\n",
      "阈值=0.850: Accuracy=0.8564, F1=0.8456, Recall=0.7734, Score=0.8333\n",
      "阈值=0.855: Accuracy=0.8564, F1=0.8450, Recall=0.7702, Score=0.8323\n",
      "阈值=0.860: Accuracy=0.8532, F1=0.8410, Recall=0.7635, Score=0.8279\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义collate_fn，将InputExample对象转换为适合模型输入的格式。\n",
    "    \"\"\"\n",
    "    sentences1 = [example.texts[0] for example in batch]\n",
    "    sentences2 = [example.texts[1] for example in batch]\n",
    "    labels = [example.label for example in batch]\n",
    "    return {\n",
    "        'sentences1': sentences1,\n",
    "        'sentences2': sentences2,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "class SentencePairDataset:\n",
    "    def __init__(self, sentences1, sentences2, labels):\n",
    "        self.examples = [InputExample(texts=[s1, s2], label=float(label))\n",
    "                         for s1, s2, label in zip(sentences1, sentences2, labels)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def evaluate(model, data_loader, device, threshold=0.84):\n",
    "    \"\"\"\n",
    "    高效评估函数，批量编码所有句子对并计算相似度。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings1 = []\n",
    "    all_embeddings2 = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 批量编码所有句子对\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            sentences1 = batch['sentences1']\n",
    "            sentences2 = batch['sentences2']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            embeddings1 = model.encode(sentences1, convert_to_tensor=True, device=device)\n",
    "            embeddings2 = model.encode(sentences2, convert_to_tensor=True, device=device)\n",
    "\n",
    "            all_embeddings1.append(embeddings1)\n",
    "            all_embeddings2.append(embeddings2)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # 将所有嵌入拼接为单个张量\n",
    "    all_embeddings1 = torch.cat(all_embeddings1, dim=0)\n",
    "    all_embeddings2 = torch.cat(all_embeddings2, dim=0)\n",
    "    all_labels = torch.tensor(all_labels, dtype=torch.int, device=device)\n",
    "\n",
    "    # 一次性计算余弦相似度\n",
    "    similarity = torch.cosine_similarity(all_embeddings1, all_embeddings2, dim=1)\n",
    "    preds = (similarity > threshold).cpu().numpy().astype(int)\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(all_labels.cpu().numpy(), preds)\n",
    "    f1 = f1_score(all_labels.cpu().numpy(), preds)\n",
    "    recall = recall_score(all_labels.cpu().numpy(), preds)\n",
    "    score = 0.6 * f1 + 0.2 * accuracy + 0.2 * recall\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "        'score': score,\n",
    "        'similarity': similarity.cpu().numpy(),  # 返回相似度分数用于进一步分析\n",
    "        'labels': all_labels.cpu().numpy()       # 返回真实标签用于进一步分析\n",
    "    }\n",
    "\n",
    "def test_best_model(test_file='csv/test.csv', model_path='best_model', batch_size=96, threshold=0.84):\n",
    "    \"\"\"\n",
    "    加载最佳模型并在测试集上验证性能\n",
    "    \n",
    "    Args:\n",
    "        test_file: 测试集文件路径\n",
    "        model_path: 模型保存路径\n",
    "        batch_size: 批处理大小\n",
    "        threshold: 相似度阈值，用于确定样本是否属于同一类\n",
    "        \n",
    "    Returns:\n",
    "        dict: 包含测试指标的字典\n",
    "    \"\"\"\n",
    "    # 检查CUDA\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 1. 加载测试数据\n",
    "    print(\"加载测试数据...\")\n",
    "    test_data = pd.read_csv(test_file, sep='\\t', header=None, names=['q1', 'q2', 'label'])\n",
    "    print(f\"测试集大小: {len(test_data)}\")\n",
    "    \n",
    "    # 2. 加载最佳模型\n",
    "    print(f\"\\n加载模型 {model_path}...\")\n",
    "    try:\n",
    "        model = SentenceTransformer(model_path)\n",
    "        model.to(device)\n",
    "        print(\"模型加载成功\")\n",
    "        print(f\"模型是否在GPU上: {next(model.parameters()).device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"模型加载失败: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 3. 准备测试集\n",
    "    print(\"准备测试集...\")\n",
    "    test_dataset = SentencePairDataset(\n",
    "        test_data['q1'].tolist(),\n",
    "        test_data['q2'].tolist(),\n",
    "        test_data['label'].tolist()\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # 不使用多进程\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    # 4. 进行测试评估\n",
    "    print(\"进行测试评估...\")\n",
    "    test_metrics = evaluate(model, test_loader, device, threshold)\n",
    "    \n",
    "    # 5. 输出结果\n",
    "    print(\"\\n测试结果:\")\n",
    "    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1-score: {test_metrics['f1']:.4f}\")\n",
    "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"最终得分: {test_metrics['score']:.4f}\")\n",
    "    \n",
    "    # 6. 分析不同阈值的结果\n",
    "    print(\"\\n尝试不同阈值:\")\n",
    "    for th in [0.84, 0.845, 0.85, 0.855, 0.86]:\n",
    "        preds = (test_metrics['similarity'] > th).astype(int)\n",
    "        acc = accuracy_score(test_metrics['labels'], preds)\n",
    "        f1 = f1_score(test_metrics['labels'], preds)\n",
    "        recall = recall_score(test_metrics['labels'], preds)\n",
    "        score = 0.6 * f1 + 0.2 * acc + 0.2 * recall\n",
    "        print(f\"阈值={th:.3f}: Accuracy={acc:.4f}, F1={f1:.4f}, Recall={recall:.4f}, Score={score:.4f}\")\n",
    "    \n",
    "    return test_metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 运行测试\n",
    "    test_metrics = test_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41b54d",
   "metadata": {},
   "source": [
    "threshold=0.84  0.8947 0.8358"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c05a9",
   "metadata": {},
   "source": [
    "threshold=0.85 0.8929 0.8359"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ca9bc",
   "metadata": {},
   "source": [
    "threshold=0.855 0.8868 0.8369"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2102a63",
   "metadata": {},
   "source": [
    "threshold=0.86 0.8858 0.8350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c951a4",
   "metadata": {},
   "source": [
    "threshold=0.845 0.8893 0.8351"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
