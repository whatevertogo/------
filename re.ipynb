{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e34162",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import requests\n",
    "\n",
    "# 设置随机种子\n",
    "#torch.manual_seed(42)\n",
    "#np.random.seed(42)\n",
    "\n",
    "# 检查CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(timedelta(seconds=int(seconds)))\n",
    "\n",
    "def check_internet_connection():\n",
    "    try:\n",
    "        requests.get(\"https://huggingface.co\", timeout=5)\n",
    "        print(\"网络连接正常。\")\n",
    "    except requests.ConnectionError:\n",
    "        print(\"网络连接失败，请检查网络。\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67997b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义collate_fn，将InputExample对象转换为适合模型输入的格式。\n",
    "    \"\"\"\n",
    "    sentences1 = [example.texts[0] for example in batch]\n",
    "    sentences2 = [example.texts[1] for example in batch]\n",
    "    labels = [example.label for example in batch]\n",
    "    return {\n",
    "        'sentences1': sentences1,\n",
    "        'sentences2': sentences2,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "class SentencePairDataset:\n",
    "    def __init__(self, sentences1, sentences2, labels):\n",
    "        self.examples = [InputExample(texts=[s1, s2], label=float(label))\n",
    "                         for s1, s2, label in zip(sentences1, sentences2, labels)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def evaluate(model, data_loader, device, threshold=0.84):\n",
    "    \"\"\"\n",
    "    高效评估函数，批量编码所有句子对并计算相似度。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings1 = []\n",
    "    all_embeddings2 = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 批量编码所有句子对\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            sentences1 = batch['sentences1']\n",
    "            sentences2 = batch['sentences2']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            embeddings1 = model.encode(sentences1, convert_to_tensor=True, device=device)\n",
    "            embeddings2 = model.encode(sentences2, convert_to_tensor=True, device=device)\n",
    "\n",
    "            all_embeddings1.append(embeddings1)\n",
    "            all_embeddings2.append(embeddings2)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # 将所有嵌入拼接为单个张量\n",
    "    all_embeddings1 = torch.cat(all_embeddings1, dim=0)\n",
    "    all_embeddings2 = torch.cat(all_embeddings2, dim=0)\n",
    "    all_labels = torch.tensor(all_labels, dtype=torch.int, device=device)\n",
    "\n",
    "    # 一次性计算余弦相似度\n",
    "    similarity = torch.cosine_similarity(all_embeddings1, all_embeddings2, dim=1)\n",
    "    preds = (similarity > threshold).cpu().numpy().astype(int)\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(all_labels.cpu().numpy(), preds)\n",
    "    f1 = f1_score(all_labels.cpu().numpy(), preds)\n",
    "    recall = recall_score(all_labels.cpu().numpy(), preds)\n",
    "    score = 0.6 * f1 + 0.2 * accuracy + 0.2 * recall\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "        'score': score\n",
    "    }\n",
    "\n",
    "def train_model(model, train_data, val_data, device, batch_size=64, epochs=3, patience=3, min_delta=1e-4):\n",
    "    \"\"\"\n",
    "    完全重写的训练函数，包含学习率调度器\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    print(f\"模型是否在GPU上: {next(model.parameters()).device}\")\n",
    "    \n",
    "    # 准备数据集\n",
    "    print(\"准备训练数据集...\")\n",
    "    train_dataset = SentencePairDataset(\n",
    "        train_data['q1'].tolist(),\n",
    "        train_data['q2'].tolist(),\n",
    "        train_data['label'].tolist()\n",
    "    )\n",
    "    print(\"准备验证数据集...\")\n",
    "    val_dataset = SentencePairDataset(\n",
    "        val_data['q1'].tolist(),\n",
    "        val_data['q2'].tolist(),\n",
    "        val_data['label'].tolist()\n",
    "    )\n",
    "    \n",
    "    # 数据加载器\n",
    "    print(\"创建数据加载器...\")\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # Windows下使用0避免多进程问题\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    # 优化器和损失函数\n",
    "    print(\"初始化优化器和损失函数...\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    # 添加学习率调度器\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, \n",
    "                                verbose=True, min_lr=1e-6)\n",
    "    train_loss = losses.CosineSimilarityLoss(model)\n",
    "    best_score = 0\n",
    "    no_improve_epochs = 0\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    print(\"开始训练循环...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        progress_bar = tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        try:\n",
    "            for batch_idx, batch in enumerate(train_dataloader):\n",
    "                # 获取数据\n",
    "                sentences1 = batch['sentences1']\n",
    "                sentences2 = batch['sentences2']\n",
    "                labels = torch.tensor(batch['labels'], dtype=torch.float32, device=device)\n",
    "\n",
    "                # 清除梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 将句子转换为模型输入格式\n",
    "                features1 = model.tokenize(sentences1)\n",
    "                features2 = model.tokenize(sentences2)\n",
    "\n",
    "                # 将输入移动到设备上\n",
    "                features1 = {key: val.to(device) for key, val in features1.items()}\n",
    "                features2 = {key: val.to(device) for key, val in features2.items()}\n",
    "\n",
    "                # 计算余弦相似度损失\n",
    "                loss = train_loss([features1, features2], labels)\n",
    "\n",
    "                # 反向传播\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # 更新进度条\n",
    "                total_loss += loss.item()\n",
    "                progress_bar.update(1)\n",
    "                progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            # 进行验证\n",
    "            val_metrics = evaluate(model, val_dataloader, device)\n",
    "            current_score = val_metrics['score']\n",
    "            \n",
    "            # 更新学习率\n",
    "            scheduler.step(current_score)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            print(f\"当前学习率: {current_lr:.2e}\")\n",
    "            print(f\"验证集评估: Accuracy={val_metrics['accuracy']:.4f}, \"\n",
    "                  f\"F1={val_metrics['f1']:.4f}, Recall={val_metrics['recall']:.4f}\")\n",
    "            print(f\"当前得分: {current_score:.4f}\")\n",
    "            \n",
    "            # 保存每个epoch的模型\n",
    "            epoch_save_path = f'model_epoch_{epoch+1}'\n",
    "            print(f\"保存当前epoch模型到: {epoch_save_path}\")\n",
    "            model.save(epoch_save_path)\n",
    "            \n",
    "            # 检查是否需要保存最佳模型\n",
    "            if current_score > best_score + min_delta:\n",
    "                best_score = current_score\n",
    "                no_improve_epochs = 0\n",
    "                print(f\"保存最佳模型，得分: {best_score:.4f}\")\n",
    "                model.save('best_model')\n",
    "            else:\n",
    "                no_improve_epochs += 1\n",
    "                print(f\"模型表现未提升，已经 {no_improve_epochs}/{patience} 个epoch\")\n",
    "                if no_improve_epochs >= patience:\n",
    "                    print(\"\\nEarly stopping triggered\")\n",
    "                    break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"训练过程中出错: {e}\")\n",
    "            progress_bar.close()\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a645d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n",
      "训练集大小: 214889\n",
      "验证集大小: 23877\n",
      "测试集大小: 4401\n",
      "\n",
      "训练集类别分布:\n",
      "label\n",
      "1    124695\n",
      "0     90194\n",
      "Name: count, dtype: int64\n",
      "训练集大小: 214889\n",
      "验证集大小: 23877\n",
      "测试集大小: 4401\n",
      "\n",
      "训练集类别分布:\n",
      "label\n",
      "1    124695\n",
      "0     90194\n",
      "Name: count, dtype: int64\n",
      "网络连接正常。\n",
      "\n",
      "加载预训练模型...\n",
      "网络连接正常。\n",
      "\n",
      "加载预训练模型...\n",
      "预训练模型加载成功！\n",
      "\n",
      "开始训练...\n",
      "模型是否在GPU上: cuda:0\n",
      "准备训练数据集...\n",
      "预训练模型加载成功！\n",
      "\n",
      "开始训练...\n",
      "模型是否在GPU上: cuda:0\n",
      "准备训练数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\18794\\Desktop\\比赛\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备验证数据集...\n",
      "创建数据加载器...\n",
      "初始化优化器和损失函数...\n",
      "开始训练循环...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 6716/6716 [26:49<00:00,  5.33it/s, loss=0.0685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "当前学习率: 2.00e-05\n",
      "验证集评估: Accuracy=0.8726, F1=0.8804, Recall=0.8069\n",
      "当前得分: 0.8642\n",
      "保存当前epoch模型到: model_epoch_1\n",
      "保存最佳模型，得分: 0.8642\n",
      "保存最佳模型，得分: 0.8642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 6716/6716 [27:32<00:00,  4.06it/s, loss=0.0685]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "当前学习率: 2.00e-05\n",
      "验证集评估: Accuracy=0.8957, F1=0.9049, Recall=0.8541\n",
      "当前得分: 0.8929\n",
      "保存当前epoch模型到: model_epoch_2\n",
      "保存最佳模型，得分: 0.8929\n",
      "保存最佳模型，得分: 0.8929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 6716/6716 [25:54<00:00,  4.32it/s, loss=0.0636]\n",
      "Epoch 3/10:   0%|          | 1/6716 [00:00<22:41,  4.93it/s, loss=0.0691]\n",
      "Epoch 3/10: 100%|██████████| 6716/6716 [24:52<00:00,  5.13it/s, loss=0.0682]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "当前学习率: 2.00e-05\n",
      "验证集评估: Accuracy=0.8933, F1=0.9025, Recall=0.8493\n",
      "当前得分: 0.8900\n",
      "保存当前epoch模型到: model_epoch_3\n",
      "模型表现未提升，已经 1/2 个epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 6716/6716 [25:36<00:00,  4.37it/s, loss=0.0682]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "def main_v2():\n",
    "    # 1. 加载数据\n",
    "    print(\"加载数据...\")\n",
    "    data = pd.read_csv('csv/train.tsv', sep='\\t', header=None, names=['q1', 'q2', 'label'])\n",
    "    test_data = pd.read_csv('csv/test.csv', sep='\\t', header=None, names=['q1', 'q2', 'label'])\n",
    "\n",
    "    # 拆分训练集和验证集 (添加随机种子确保可复现)\n",
    "    train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "    print(f\"训练集大小: {len(train_data)}\")\n",
    "    print(f\"验证集大小: {len(val_data)}\")\n",
    "    print(f\"测试集大小: {len(test_data)}\")\n",
    "    print(\"\\n训练集类别分布:\")\n",
    "    print(train_data['label'].value_counts())\n",
    "\n",
    "    # 2. 检查网络连接\n",
    "    if not check_internet_connection():\n",
    "        return\n",
    "\n",
    "    # 3. 加载模型\n",
    "    print(\"\\n加载预训练模型...\")\n",
    "    try:\n",
    "        model = SentenceTransformer('shibing624/text2vec-base-chinese')\n",
    "        print(\"预训练模型加载成功！\")\n",
    "    except Exception as e:\n",
    "        print(f\"预训练模型加载失败: {e}\")\n",
    "        print(\"请检查网络连接或模型名称是否正确。\")\n",
    "        return\n",
    "\n",
    "    # 4. 训练模型（改进的超参数）\n",
    "    print(\"\\n开始训练...\")\n",
    "    model = train_model(model, train_data, val_data, device, \n",
    "                   batch_size=32,     # 减小批次大小以提高泛化性\n",
    "                   epochs=10,         # 增加轮次以便更好地观察模型表现\n",
    "                   patience=2,        # 降低patience以更快响应性能下降\n",
    "                   min_delta=1e-3)    # 提高阈值以确保显著改进\n",
    "\n",
    "    # 5. 加载最佳模型进行测试\n",
    "    print(\"\\n加载最佳模型进行测试...\")\n",
    "    try:\n",
    "        model = SentenceTransformer('best_model')\n",
    "        print(\"模型加载成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"模型加载失败: {e}\")\n",
    "        return\n",
    "\n",
    "    # 6. 准备测试集（保持与训练时相同的batch_size）\n",
    "    print(\"准备测试集...\")\n",
    "    test_dataset = SentencePairDataset(\n",
    "        test_data['q1'].tolist(),\n",
    "        test_data['q2'].tolist(),\n",
    "        test_data['label'].tolist()\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=32,  # 与训练时保持一致\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "\n",
    "    # 7. 最终测试（使用多个阈值）\n",
    "    print(\"进行最终测试...\")\n",
    "    thresholds = [0.80, 0.82, 0.84, 0.85, 0.86, 0.88]\n",
    "    best_threshold = 0.84\n",
    "    best_score = 0\n",
    "\n",
    "    try:\n",
    "        base_metrics = evaluate(model, test_loader, device)\n",
    "        print(\"\\n基准测试结果:\")\n",
    "        print(f\"阈值=0.84 (默认):\")\n",
    "        print(f\"Accuracy: {base_metrics['accuracy']:.4f}\")\n",
    "        print(f\"F1-score: {base_metrics['f1']:.4f}\")\n",
    "        print(f\"Recall: {base_metrics['recall']:.4f}\")\n",
    "        print(f\"得分: {base_metrics['score']:.4f}\")\n",
    "\n",
    "        # 测试不同阈值\n",
    "        print(\"\\n尝试不同阈值:\")\n",
    "        for threshold in thresholds:\n",
    "            metrics = evaluate(model, test_loader, device, threshold=threshold)\n",
    "            score = metrics['score']\n",
    "            print(f\"\\n阈值={threshold:.3f}:\")\n",
    "            print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(f\"F1-score: {metrics['f1']:.4f}\")\n",
    "            print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "            print(f\"得分: {score:.4f}\")\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_threshold = threshold\n",
    "                \n",
    "        print(f\"\\n最佳阈值: {best_threshold:.3f}, 最佳得分: {best_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"测试失败: {e}\")\n",
    "        return\n",
    "\n",
    "    # 8. 使用最佳阈值保存最终评估结果\n",
    "    final_metrics = evaluate(model, test_loader, device, threshold=best_threshold)\n",
    "    print(\"\\n使用最佳阈值的最终结果:\")\n",
    "    print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1-score: {final_metrics['f1']:.4f}\")\n",
    "    print(f\"Recall: {final_metrics['recall']:.4f}\")\n",
    "    print(f\"最终得分: {final_metrics['score']:.4f}\")\n",
    "\n",
    "    # 9. 保存最终模型\n",
    "    model.save('chinese_semantic_model_final')\n",
    "    print(\"\\n模型已保存为: chinese_semantic_model_final\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4767c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分训练集和验证集 (添加随机种子确保可复现)\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"训练集大小: {len(train_data)}\")\n",
    "print(f\"验证集大小: {len(val_data)}\")\n",
    "print(f\"测试集大小: {len(test_data)}\")\n",
    "print(\"\\n训练集类别分布:\")\n",
    "print(train_data['label'].value_counts())\n",
    "\n",
    "# 2. 检查网络连接\n",
    "if not check_internet_connection():\n",
    "    return\n",
    "\n",
    "# 3. 加载模型\n",
    "print(\"\\n加载预训练模型...\")\n",
    "try:\n",
    "    model = SentenceTransformer('shibing624/text2vec-base-chinese')\n",
    "    print(\"预训练模型加载成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"预训练模型加载失败: {e}\")\n",
    "    print(\"请检查网络连接或模型名称是否正确。\")\n",
    "    return\n",
    "\n",
    "# 4. 训练模型（改进的超参数）\n",
    "print(\"\\n开始训练...\")\n",
    "model = train_model(model, train_data, val_data, device, \n",
    "               batch_size=32,     # 减小批次大小以提高泛化性\n",
    "               epochs=10,         # 增加轮次以便更好地观察模型表现\n",
    "               patience=2,        # 降低patience以更快响应性能下降\n",
    "               min_delta=1e-3)    # 提高阈值以确保显著改进\n",
    "\n",
    "# 5. 加载最佳模型进行测试\n",
    "print(\"\\n加载最佳模型进行测试...\")\n",
    "try:\n",
    "    model = SentenceTransformer('best_model')\n",
    "    print(\"模型加载成功\")\n",
    "except Exception as e:\n",
    "    print(f\"模型加载失败: {e}\")\n",
    "    return\n",
    "\n",
    "# 6. 准备测试集（保持与训练时相同的batch_size）\n",
    "print(\"准备测试集...\")\n",
    "test_dataset = SentencePairDataset(\n",
    "    test_data['q1'].tolist(),\n",
    "    test_data['q2'].tolist(),\n",
    "    test_data['label'].tolist()\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32,  # 与训练时保持一致\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=custom_collate_fn\n",
    ")\n",
    "\n",
    "# 7. 最终测试（使用多个阈值）\n",
    "print(\"进行最终测试...\")\n",
    "thresholds = [0.80, 0.82, 0.84, 0.85, 0.86, 0.88]\n",
    "best_threshold = 0.84\n",
    "best_score = 0\n",
    "\n",
    "try:\n",
    "    base_metrics = evaluate(model, test_loader, device)\n",
    "    print(\"\\n基准测试结果:\")\n",
    "    print(f\"阈值=0.84 (默认):\")\n",
    "    print(f\"Accuracy: {base_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1-score: {base_metrics['f1']:.4f}\")\n",
    "    print(f\"Recall: {base_metrics['recall']:.4f}\")\n",
    "    print(f\"得分: {base_metrics['score']:.4f}\")\n",
    "\n",
    "    # 测试不同阈值\n",
    "    print(\"\\n尝试不同阈值:\")\n",
    "    for threshold in thresholds:\n",
    "        metrics = evaluate(model, test_loader, device, threshold=threshold)\n",
    "        score = metrics['score']\n",
    "        print(f\"\\n阈值={threshold:.3f}:\")\n",
    "        print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"F1-score: {metrics['f1']:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "        print(f\"得分: {score:.4f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "            \n",
    "    print(f\"\\n最佳阈值: {best_threshold:.3f}, 最佳得分: {best_score:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"测试失败: {e}\")\n",
    "    return\n",
    "\n",
    "# 8. 使用最佳阈值保存最终评估结果\n",
    "final_metrics = evaluate(model, test_loader, device, threshold=best_threshold)\n",
    "print(\"\\n使用最佳阈值的最终结果:\")\n",
    "print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-score: {final_metrics['f1']:.4f}\")\n",
    "print(f\"Recall: {final_metrics['recall']:.4f}\")\n",
    "print(f\"最终得分: {final_metrics['score']:.4f}\")\n",
    "\n",
    "# 9. 保存最终模型\n",
    "model.save('chinese_semantic_model_final')\n",
    "print(\"\\n模型已保存为: chinese_semantic_model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ce3c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "加载测试数据...\n",
      "测试集大小: 4401\n",
      "\n",
      "加载模型 best_model...\n",
      "模型加载成功\n",
      "模型是否在GPU上: cuda:0\n",
      "准备测试集...\n",
      "进行测试评估...\n",
      "\n",
      "测试结果:\n",
      "Accuracy: 0.8278\n",
      "F1-score: 0.8087\n",
      "Recall: 0.7161\n",
      "最终得分: 0.7940\n",
      "\n",
      "尝试不同阈值:\n",
      "阈值=0.840: Accuracy=0.8278, F1=0.8087, Recall=0.7161, Score=0.7940\n",
      "阈值=0.845: Accuracy=0.8241, F1=0.8034, Recall=0.7068, Score=0.7882\n",
      "阈值=0.850: Accuracy=0.8234, F1=0.8017, Recall=0.7023, Score=0.7862\n",
      "阈值=0.855: Accuracy=0.8207, F1=0.7975, Recall=0.6947, Score=0.7816\n",
      "阈值=0.860: Accuracy=0.8187, F1=0.7941, Recall=0.6880, Score=0.7778\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义collate_fn，将InputExample对象转换为适合模型输入的格式。\n",
    "    \"\"\"\n",
    "    sentences1 = [example.texts[0] for example in batch]\n",
    "    sentences2 = [example.texts[1] for example in batch]\n",
    "    labels = [example.label for example in batch]\n",
    "    return {\n",
    "        'sentences1': sentences1,\n",
    "        'sentences2': sentences2,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "class SentencePairDataset:\n",
    "    def __init__(self, sentences1, sentences2, labels):\n",
    "        self.examples = [InputExample(texts=[s1, s2], label=float(label))\n",
    "                         for s1, s2, label in zip(sentences1, sentences2, labels)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def evaluate(model, data_loader, device, threshold=0.84):\n",
    "    \"\"\"\n",
    "    高效评估函数，批量编码所有句子对并计算相似度。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_embeddings1 = []\n",
    "    all_embeddings2 = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 批量编码所有句子对\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            sentences1 = batch['sentences1']\n",
    "            sentences2 = batch['sentences2']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            embeddings1 = model.encode(sentences1, convert_to_tensor=True, device=device)\n",
    "            embeddings2 = model.encode(sentences2, convert_to_tensor=True, device=device)\n",
    "\n",
    "            all_embeddings1.append(embeddings1)\n",
    "            all_embeddings2.append(embeddings2)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # 将所有嵌入拼接为单个张量\n",
    "    all_embeddings1 = torch.cat(all_embeddings1, dim=0)\n",
    "    all_embeddings2 = torch.cat(all_embeddings2, dim=0)\n",
    "    all_labels = torch.tensor(all_labels, dtype=torch.int, device=device)\n",
    "\n",
    "    # 一次性计算余弦相似度\n",
    "    similarity = torch.cosine_similarity(all_embeddings1, all_embeddings2, dim=1)\n",
    "    preds = (similarity > threshold).cpu().numpy().astype(int)\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(all_labels.cpu().numpy(), preds)\n",
    "    f1 = f1_score(all_labels.cpu().numpy(), preds)\n",
    "    recall = recall_score(all_labels.cpu().numpy(), preds)\n",
    "    score = 0.6 * f1 + 0.2 * accuracy + 0.2 * recall\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'recall': recall,\n",
    "        'score': score,\n",
    "        'similarity': similarity.cpu().numpy(),  # 返回相似度分数用于进一步分析\n",
    "        'labels': all_labels.cpu().numpy()       # 返回真实标签用于进一步分析\n",
    "    }\n",
    "\n",
    "def test_best_model(test_file='csv/test.csv', model_path='best_model', batch_size=64, threshold=0.84):\n",
    "    \"\"\"\n",
    "    加载最佳模型并在测试集上验证性能\n",
    "    \n",
    "    Args:\n",
    "        test_file: 测试集文件路径\n",
    "        model_path: 模型保存路径\n",
    "        batch_size: 批处理大小\n",
    "        threshold: 相似度阈值，用于确定样本是否属于同一类\n",
    "        \n",
    "    Returns:\n",
    "        dict: 包含测试指标的字典\n",
    "    \"\"\"\n",
    "    # 检查CUDA\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用设备: {device}\")\n",
    "    \n",
    "    # 1. 加载测试数据\n",
    "    print(\"加载测试数据...\")\n",
    "    test_data = pd.read_csv(test_file, sep='\\t', header=None, names=['q1', 'q2', 'label'])\n",
    "    print(f\"测试集大小: {len(test_data)}\")\n",
    "    \n",
    "    # 2. 加载最佳模型\n",
    "    print(f\"\\n加载模型 {model_path}...\")\n",
    "    try:\n",
    "        model = SentenceTransformer(model_path)\n",
    "        model.to(device)\n",
    "        print(\"模型加载成功\")\n",
    "        print(f\"模型是否在GPU上: {next(model.parameters()).device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"模型加载失败: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # 3. 准备测试集\n",
    "    print(\"准备测试集...\")\n",
    "    test_dataset = SentencePairDataset(\n",
    "        test_data['q1'].tolist(),\n",
    "        test_data['q2'].tolist(),\n",
    "        test_data['label'].tolist()\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        pin_memory=True,\n",
    "        num_workers=0,  # 不使用多进程\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    # 4. 进行测试评估\n",
    "    print(\"进行测试评估...\")\n",
    "    test_metrics = evaluate(model, test_loader, device, threshold)\n",
    "    \n",
    "    # 5. 输出结果\n",
    "    print(\"\\n测试结果:\")\n",
    "    print(f\"Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1-score: {test_metrics['f1']:.4f}\")\n",
    "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"最终得分: {test_metrics['score']:.4f}\")\n",
    "    \n",
    "    # 6. 分析不同阈值的结果\n",
    "    print(\"\\n尝试不同阈值:\")\n",
    "    for th in [0.84, 0.845, 0.85, 0.855, 0.86]:\n",
    "        preds = (test_metrics['similarity'] > th).astype(int)\n",
    "        acc = accuracy_score(test_metrics['labels'], preds)\n",
    "        f1 = f1_score(test_metrics['labels'], preds)\n",
    "        recall = recall_score(test_metrics['labels'], preds)\n",
    "        score = 0.6 * f1 + 0.2 * acc + 0.2 * recall\n",
    "        print(f\"阈值={th:.3f}: Accuracy={acc:.4f}, F1={f1:.4f}, Recall={recall:.4f}, Score={score:.4f}\")\n",
    "    \n",
    "    return test_metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 运行测试\n",
    "    test_metrics = test_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41b54d",
   "metadata": {},
   "source": [
    "threshold=0.84  0.8947 0.8358"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c05a9",
   "metadata": {},
   "source": [
    "threshold=0.85 0.8929 0.8359"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ca9bc",
   "metadata": {},
   "source": [
    "threshold=0.855 0.8868 0.8369"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2102a63",
   "metadata": {},
   "source": [
    "threshold=0.86 0.8858 0.8350"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c951a4",
   "metadata": {},
   "source": [
    "threshold=0.845 0.8893 0.8351"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
